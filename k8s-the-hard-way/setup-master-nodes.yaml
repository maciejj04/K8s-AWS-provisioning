# TODO: Refactor all script invocations to use ansible _script_ module.
- hosts: localhost
  gather_facts: no
  tasks:
    - include_vars:
        file: "{{ item }}"
      loop:
        - vars/commons.yaml
        - vars/master.yaml
      tags:
        - always

    - name: Check mandatory variables
      fail:
        msg: "{{ item }} was not defined!"
      when: vars[item] is undefined
      loop:
        - etcd_download_url
        - master_ips
        - masters_internal_ips
        - cluster_cidr
        #TODO: for now assume that masters_internal_ips will be provided manually, this is to be automated in the future.
      tags:
        - always

    - name: Generate encryption config for etcd
      shell: ./generate_encryption_config.sh
      args:
        chdir: "{{ playbook_dir }}/encryption"

    # TODO: 10.32.0.10 or 10.32.0.1? https://github.com/prabhatsharma/kubernetes-the-hard-way-aws/issues/2
    - name: Create Api Server Certificate
      shell: cfssl gencert -ca=../ca.pem -ca-key=../ca-key.pem -config=../ca-config.json -hostname='10.32.0.1,{{ clusterDNS }},{{ masters_internal_ips }},{{ k8s_public_host }},127.0.0.1,kubernetes.default' -profile=kubernetes ../master/kubernetes-csr.json | cfssljson -bare kubernetes
      args:
        chdir: "{{ playbook_dir }}/ca_tls/master"

    - name: Create The Scheduler&Controller-Manager&service-account Client Certificates
      shell: cfssl gencert -ca=../ca.pem -ca-key=../ca-key.pem -config=../ca-config.json -profile=kubernetes {{ playbook_dir }}/ca_tls/master/{{ item }}-csr.json | cfssljson -bare {{ item }}
      args:
        chdir: "{{ playbook_dir }}/ca_tls/master"
      loop:
        - kube-controller-manager
        - kube-scheduler
        - service-account

    - name: Generate kubeconfig for masters components
      include_tasks: k8s_components_kubeconfigs/generate_master_components_kubeconfigs.yaml
      loop:
        - kube-controller-manager
        - kube-scheduler
      loop_control:
        loop_var: component_name

    - name: Generate admin kubeconfig
      import_tasks: k8s_components_kubeconfigs/prepare_admin_kubeconfig.yaml

- hosts: master-nodes
  name: Setup master nodes
  user: ubuntu
  gather_facts: no
  tasks:
    - include_vars:
        file: "{{ item }}"
      loop:
        - vars/commons.yaml
        - vars/master.yaml
      tags:
        - always

    - name: Set host index
      set_fact:
        host_idx: "{{ play_hosts.index(inventory_hostname) }}"
      tags:
        - always

    - name: Copy certs, kubeconfigs and encryption config to master nodes
      copy:
        src: "{{ item.src }}"
        dest: ~/
      with_items:
        - { src: './ca_tls/ca.pem' }
        - { src: './ca_tls/ca-key.pem' }
        - { src: './ca_tls/master/kubernetes.pem' }
        - { src: './ca_tls/master/kubernetes-key.pem' }
        - { src: './ca_tls/master/service-account.pem' }
        - { src: './ca_tls/master/service-account-key.pem' }
        - { src: 'k8s_components_kubeconfigs/kube-controller-manager.kubeconfig'}
        - { src: 'k8s_components_kubeconfigs/kube-scheduler.kubeconfig'}
        - { src: 'k8s_components_kubeconfigs/admin.kubeconfig'}
        - { src: 'encryption/encryption-config.yaml'}
        - { src: '{{ playbook_dir }}/etcd/create_etcd_service_definition.sh'}
#      when:

    - name: Download etcd binaries
      get_url: url={{ etcd_download_url }} dest=~/
#     when:

    # TODO: Check if this works on ubuntu 18.04 machine
    - name: Extract etcd archive
      unarchive: src=etcd-v3.3.9-linux-amd64.tar.gz dest=~ remote_src=yes

    - command: pwd
      register: base_user_home
      tags:
        - always

    - name: Move etcd binaries
      become: true
      command: "mv {{ base_user_home.stdout }}/etcd-v3.3.9-linux-amd64/{{ item }} /usr/local/bin/"
      loop:
        - etcd
        - etcdctl

    # This should in future just ensure that appropriate volume is mounted to the instance in specified path for --data-dir.
    - name: Create etcd directories
      become: true
      file:
        path: "{{ item }}"
        state: directory
      loop:
        - /etc/etcd
        - /var/lib/etcd
      tags:
        - etcd

    - name: Copy secrets to etcd
      become: true
      copy:
        src: "{{ item.src }}"
        dest: /etc/etcd/
        remote_src: yes
      with_items:
        - { src: "{{ base_user_home.stdout }}/ca.pem" }
        - { src: "{{ base_user_home.stdout }}/kubernetes.pem" }
        - { src: "{{ base_user_home.stdout }}/kubernetes-key.pem" }
      tags:
        - etcd

    - name: Set host name
      command: hostname -s
      register: hostname
      tags:
        - always

    - name: Make create_etcd_service_definition.sh executable
      file: dest="{{ base_user_home.stdout }}/create_etcd_service_definition.sh" mode=a+x

    - name: Get current host external ip
      set_fact:
        host_ip: "{{ hostvars[inventory_hostname].inventory_hostname }}"
      tags:
        - always

    - name: Get current host internal ip
      command: hostname -I
      register: host_internal_ip_out
      tags:
        - always

    - set_fact:
        host_internal_ip: "{{ host_internal_ip_out.stdout | trim }}"
      tags:
        - always

    - debug:
        msg: "Set host_internal_ip  to {{ host_internal_ip }}"

    - name: Prepare masters internal ip list
      set_fact:
        master_peers_internal_ips_list:  "{{ masters_internal_ips.split(',') | difference([ host_internal_ip ]) | join(',') }}"

    - name: Peers ips
      debug:
        msg: "{{ master_peers_internal_ips_list }}"

    - name: Create etcd service definition
      command: "./create_etcd_service_definition.sh --name=etcd{{host_idx}} --index={{ host_idx }} --internal-ip={{ host_internal_ip }} --etcd-hosts-ips={{ master_peers_internal_ips_list }}"
      args:
        chdir: "{{ base_user_home.stdout }}"

    - name: move etcd service definitions
      become: true
      copy:
        src: "{{ item.src }}"
        dest: /etc/systemd/system/
        remote_src: yes
      with_items:
        - { src: "{{ base_user_home.stdout }}/etcd.service" }

    - name: Reload systemd to reread configs
      become: true
      systemd:
        daemon_reload: yes

    - name: Enable etcd service
      become: true
      systemd:
        name: etcd
        enabled: yes

    - name: Start etcd service
      become: true
      systemd:
        name: etcd
        state: started

      # Validate via rc?
    - name: Validate etcd cluster health
      become: true
      command: etcdctl --ca-file=/etc/etcd/ca.pem cluster-health
      register: result
      until: result.stdout.find("cluster is healthy") != -1
      retries: 6
      delay: 10

    # ============================================ K8s control plane setup ============================================
    - name: Create K8s configuration directory
      become: true
      file:
        path: /etc/kubernetes/config
        state: directory
      tags:
        - control-plane

    - name: Pull control plane binaries
      get_url: url={{ item }} dest=~/
      loop:
        - "{{ kube_apiserver_download_url }}"
        - "{{ kube_controller_manager_download_url }}"
        - "{{ kube_scheduler_download_url }}"
        - "{{ kubectl_download_url }}"
#      when:
#        -
      tags:
        - control-plane

    # chmod +x kube-apiserver kube-controller-manager kube-scheduler kubectl
    - name: Chmod on control plane
      file: dest="{{ item }}" mode=+x
      loop:
        - kube-apiserver
        - kube-controller-manager
        - kube-scheduler
        - kubectl
      tags:
        - control-plane

    # sudo mv kube-apiserver kube-controller-manager kube-scheduler kubectl /usr/local/bin/
    - name: Move control plane binaries
      become: true
      command: "mv {{ item }} /usr/local/bin/"
      loop:
        - kube-apiserver
        - kube-controller-manager
        - kube-scheduler
        - kubectl
      tags:
        - control-plane

    # Configure api-server
    - name: Create api-server directory
      become: true
      file:
        path: /var/lib/kubernetes/
        state: directory
      tags:
        - control-plane

    - name: Move secrets
      become: true
      copy:
        remote_src: yes
        src: "{{ base_user_home.stdout }}/{{ item }}"
        dest: /var/lib/kubernetes/
      loop:
        - ca.pem
        - ca-key.pem
        - kubernetes-key.pem
        - kubernetes.pem
        - encryption-config.yaml
        - service-account.pem
        - service-account-key.pem
      tags:
        - control-plane

    - name: Get vars necessary for api-server service definition
      set_fact:
        master_hosts_count: "{{ groups['master-nodes'] | length }}"
        etcd_servers: "{{ masters_internal_ips.split(',') | map('regex_replace', '(.*)', 'https://\\1:2379') | join(',') }}"

    - name: Create service definitions for master binaries
      local_action: template src="{{ playbook_dir }}/service.definitions/{{ item }}-template.service" dest="{{ playbook_dir }}/service.definitions/{{ item }}.service"
      loop:
        - kube-apiserver
        - kube-controller-manager
        - kube-scheduler

    #  Refactor to use 'copy' module to copy all service definitions at once.
    - name: Copy master binaries service definitions to remotes
      become: true
      copy:
        src: "{{ playbook_dir }}/service.definitions/{{ item }}.service"
        dest: /etc/systemd/system/
      loop:
        - kube-apiserver
        - kube-controller-manager
        - kube-scheduler
      tags:
        - control-plane

    - name: Move kubeconfigs to appropriate location
      become: true
      copy:
        remote_src: yes
        src: "{{ base_user_home.stdout }}/{{ item }}"
        dest: /var/lib/kubernetes
      loop:
        - kube-controller-manager.kubeconfig
        - kube-scheduler.kubeconfig
      tags:
        - control-plane

    - name: Copy kube-scheduler.yaml to remotes
      become: true
      copy:
        src: "{{ playbook_dir }}/k8s_components_configuration/kube-scheduler.yaml"
        dest: /etc/kubernetes/config/kube-scheduler.yaml

    - name: Reload systemd to reread configs
      become: true
      systemd:
        daemon_reload: yes
      tags:
        - start_components

    - name: Enable control plane services
      become: true
      systemd:
        name: "{{ item }}"
        enabled: yes
      loop:
        - kube-apiserver
        - kube-controller-manager
        - kube-scheduler
      tags:
        - start_components

    - name: Start control plane services
      become: true
      systemd:
        name: "{{ item }}"
        state: started
      loop:
        - kube-apiserver
        - kube-controller-manager
        - kube-scheduler
      tags:
        - start_components

    - name: Restart control plane services
      become: true
      systemd:
        name: "{{ item }}"
        state: restarted
      loop:
        - kube-apiserver
        - kube-controller-manager
        - kube-scheduler
      tags: [ 'restart_components', 'never' ]

- hosts: localhost
  gather_facts: no
  tasks:
    - name: Prepare ips
      set_fact:
        master_public_ips_list: "{{ master_ips.split(',') }}"
      tags:
        - validate-health

    - name: Validate api server(s) health
      uri:
        url: "https://{{ item }}:6443/healthz"
        status_code: 200
        validate_certs: no
      retries: 20
      delay: 5
      loop: "{{ master_public_ips_list }}"
      tags:
        - validate-health

    - name: Verify api server access via frontend LB
      uri:
        url: "https://{{ k8s_public_host }}/healthz"
        status_code: 200
        validate_certs: no
      retries: 3
      delay: 5
      tags:
        - validate-health

- hosts: master-nodes[0]
  gather_facts: no
  tasks:
    - name: Create apiserver to kubelet cluster role
      command: kubectl apply --kubeconfig {{ playbook_dir }}/k8s_components_kubeconfigs/admin.kubeconfig -f {{ playbook_dir }}/k8s_components_configuration/kubeapi-to-kubelet-cluster-role.yaml
      tags:
        - test

    - name: Create apiserver to kubelet cluster role binding
      command: kubectl apply --kubeconfig {{ playbook_dir }}/k8s_components_kubeconfigs/admin.kubeconfig -f {{ playbook_dir }}/k8s_components_configuration/kubeapi-to-kubelet-cluster-role-binding.yaml
      tags:
        - test

# TODO:
#    - name: kubectl get componentstatuses
#      command: kubectl get componentstatuses


# TODO: cleanup ~ dir